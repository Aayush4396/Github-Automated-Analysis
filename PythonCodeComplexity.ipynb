{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtmZ4NMzgMj2",
        "outputId": "5735b14d-7732-4ae9-cba3-4ab6a202db6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyGithub\n",
            "  Downloading PyGithub-1.58.2-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.5/312.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated (from PyGithub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGithub)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub) (2.27.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (40.0.2)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub) (1.15.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub) (3.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->PyGithub) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.21)\n",
            "Installing collected packages: pyjwt, deprecated, pynacl, PyGithub\n",
            "Successfully installed PyGithub-1.58.2 deprecated-1.2.14 pyjwt-2.7.0 pynacl-1.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install PyGithub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOIekMoP4SIt",
        "outputId": "4a78b185-d89e-4de3-e3e7-9cace1819ee3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9f9w3Z7-f8J3"
      },
      "outputs": [],
      "source": [
        "from github import Github, GithubException\n",
        "import nbformat\n",
        "import re\n",
        "import requests\n",
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a5pbgFzMuLjA"
      },
      "outputs": [],
      "source": [
        "github_access_token = '<Your Github api token here>'\n",
        "chatGPT_access_token = '<Your ChatGPT api token here>'\n",
        "openai.api_key = chatGPT_access_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "10TX9lPYiqkc"
      },
      "outputs": [],
      "source": [
        "client = Github(github_access_token)\n",
        "username = 'aayush4396'\n",
        "user_url = f'https://github.com/{username}'\n",
        "user_id = user_url.split('/')[-1]\n",
        "user = client.get_user(user_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all repo folders, files, content path containing only ipynb and py files in a repo"
      ],
      "metadata": {
        "id": "Z8pyza6gyo3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_files(contents):\n",
        "  files = []\n",
        "  while contents:\n",
        "    file_content = contents.pop(0)\n",
        "    if file_content.type == \"dir\":\n",
        "      contents.extend(repo.get_contents(file_content.path))\n",
        "    else:\n",
        "      file_type = file_content.name.split('.')[-1]\n",
        "      if file_type=='ipynb' or file_type=='py':\n",
        "        files.append(file_content)\n",
        "  return files"
      ],
      "metadata": {
        "id": "SVsf5j9QxyU9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_dict = {}\n",
        "for repo in user.get_repos():\n",
        "  try:\n",
        "    contents = repo.get_contents('')\n",
        "  except GithubException:\n",
        "    print('Empty Repo')\n",
        "  file_content = get_files(contents)\n",
        "  if len(file_content)!=0:\n",
        "    repo_dict[repo.name] = file_content"
      ],
      "metadata": {
        "id": "Eb5NoQqcqdN3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No. of Repos"
      ],
      "metadata": {
        "id": "cJns26Cf1eNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(repo_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCm7IdzFyzNT",
        "outputId": "9ac41598-c707-4ffc-9c55-00e7cf74c600"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. format_nb() Function to clean a notebook if ipynb.\n",
        "2. clean_code() Function to clean the code, removing import, comments, etc"
      ],
      "metadata": {
        "id": "bIRo0Ey01gg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_nb(notebook_content):\n",
        "  # Parse the notebook content\n",
        "  notebook = nbformat.reads(notebook_content, as_version=nbformat.NO_CONVERT)\n",
        "  code_cells = []\n",
        "  for cell in notebook.cells:\n",
        "      if cell.cell_type == 'code':\n",
        "          code_cells.append(cell.source)\n",
        "\n",
        "  return code_cells\n",
        "\n",
        "def clean_code(code):\n",
        "  x = '\\n'.join(code)\n",
        "  x = re.sub(r'import.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'#.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'\\'\\'\\'.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'from.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'!pip.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'pd.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'drive.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'drive.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'!gdown.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'%mat.*?(\\n|$)','',x)\n",
        "  x = re.sub(r'warn.*?(\\n|$)','',x)\n",
        "  x = re.sub('\\n','',x)\n",
        "  # x = re.sub(' ','',x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "zFshQP0udPlt"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code_clean_url() Function to clean from a list of codes of a single repo"
      ],
      "metadata": {
        "id": "QUy42-9318jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#returns the a list of codes inside the folder\n",
        "def code_clean_url(contents):\n",
        "  codes = []\n",
        "  for content in contents:\n",
        "    file_type = content.name.split('.')[-1]\n",
        "    if file_type == 'ipynb':\n",
        "\n",
        "      url_json = requests.get(content.download_url)\n",
        "      text = url_json.text\n",
        "      code = format_nb(text)\n",
        "      code_cleaned = clean_code(code)\n",
        "    else:\n",
        "      url_json = requests.get(content.download_url)\n",
        "      text = url_json.text\n",
        "      code_cleaned = clean_code(text)\n",
        "    codes.append(code_cleaned)\n",
        "\n",
        "  return codes\n"
      ],
      "metadata": {
        "id": "LcEajGptmtDr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary consisting of repo names as keys and all the ipynb/py codes as values"
      ],
      "metadata": {
        "id": "qIUdUas_3OW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codes_dict = {}\n",
        "for repo_name, contents in repo_dict.items():\n",
        "  codes_dict[repo_name] = code_clean_url(contents)"
      ],
      "metadata": {
        "id": "cDlK445X4gfO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "various prompts to get the score and reason"
      ],
      "metadata": {
        "id": "y9xuQlOH3YSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_part = 'Please retain the context of a half code that I\\'m sharing with you. your next task will be dependant on this half:'\n",
        "no_part = \"Based on the code provided to you,rate the whole code on a scale of 1 to 100 where 1 is least complex and 100 is the most complex. Just give a numerical score, no text stricty (less than 10 tokens)\"\n",
        "no_reply = 'DON\\'T REPLY ANYTHING ON THIS PART, no words please'\n",
        "next_part = 'the next part of the code is given here:'\n",
        "score_prompt = 'Based on this half and the half that i provided you, rate the whole code on a scale of 1 to 100 where 1 is least complex and 100 is the most complex. Just give a numerical score, no text stricty (less than 10 tokens)'\n",
        "justify = 'Justify your rating in points and the number of tokens should be less than 100'"
      ],
      "metadata": {
        "id": "Xk5rz43d15TZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=0\n",
        "score=0\n",
        "scores = []\n",
        "final_scores = {}\n",
        "reasons = []\n",
        "final_reason = {}\n",
        "#for loop for going through all the repository data stored in codes_dict\n",
        "for repo_name,codes in codes_dict.items():\n",
        "  x+=1\n",
        "  num_chars = 3500\n",
        "  #Going through one repo's all the files containing ipynb and py files\n",
        "  for code in codes:\n",
        "    messages = [\n",
        "    {'role':'system', 'content':'You are an expert coder who checks the complexity of the code and returns an overall complexity score'}\n",
        "    ]\n",
        "    #If number of characters of a code is less than 3500, then below prompt will be used.\n",
        "    if len(code)<num_chars:\n",
        "      # print(len(code))\n",
        "      messages.append({'role':'user','content':no_part+'\\n'+code})\n",
        "      completion = openai.ChatCompletion.create(\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "          messages=messages,\n",
        "          max_tokens=200,\n",
        "          stop=None,\n",
        "          temperature=0.1,\n",
        "          )\n",
        "      score = completion.choices[0].message.content\n",
        "\n",
        "    #If the number of characters of a code is greater than 3500, then below prompt will be used.\n",
        "    else:\n",
        "      # print(len(code))\n",
        "      parts = len(code)//num_chars\n",
        "      # print(parts)\n",
        "      for i in range(parts):\n",
        "        messages.append({'role':'user','content':first_part+'\\n'+code[i*num_chars:(i+1)*num_chars]+no_reply})\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            max_tokens=200,\n",
        "            stop=None,\n",
        "            temperature=0.1,\n",
        "            )\n",
        "        messages.append({'role':'user','content':next_part})\n",
        "\n",
        "        messages.append({'role':'user','content':score_prompt})\n",
        "        completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            max_tokens=200,\n",
        "            stop=None,\n",
        "            temperature=0.1,\n",
        "            )\n",
        "\n",
        "\n",
        "      # print(score)\n",
        "    score = completion.choices[0].message.content\n",
        "    score = re.findall('[0-9]+',score)\n",
        "    try:\n",
        "      score = float(score[0])\n",
        "    except:\n",
        "      score = 0\n",
        "    # messages = [\n",
        "    #     {'role':'system', 'content':'you have to justify your answer in less than 100 token of why you gave that score.'},\n",
        "    #     {'role':'user', 'content':justify}\n",
        "    #     ]\n",
        "    messages.append({'role':'user','content':justify})\n",
        "    completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages,\n",
        "            max_tokens=200,\n",
        "            stop=None,\n",
        "            temperature=0.1,\n",
        "            )\n",
        "    reason = completion.choices[0].message.content\n",
        "    reasons.append(reason)\n",
        "    scores.append(score)\n",
        "\n",
        "  final_reason[repo_name] = '\\n'.join(reasons)\n",
        "  final_scores[repo_name] = sum(scores)/len(scores)\n",
        "  # if x==2:\n",
        "  #   break\n",
        "if x==0:\n",
        "  print('no repo with py or ipynb file')"
      ],
      "metadata": {
        "id": "dm5_bkPMEJ7m"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can face the issue of server overload. At the moment you can only check the usernames who have lesser number of repos."
      ],
      "metadata": {
        "id": "aVEHoDyuR6V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Tr7pjIRfJv",
        "outputId": "3c2c9773-a787-4d5e-9315-6126b95781a5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Object-Classification': 85.0,\n",
              " 'Telecom-Churn-Analysis': 87.5,\n",
              " 'Twitter-Sentiment-Analysis': 81.66666666666667}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in final_scores.items():\n",
        "  if v==max(final_scores.values()):\n",
        "    print(f'Most complex repo is {k} with a score of {round(final_scores[k],2)}/100 because {final_reason[k]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoPCZlbbPEDU",
        "outputId": "c63fc4ae-f321-486f-860d-c3d1fbfd044e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most complex repo is Telecom-Churn-Analysis with a score of 87.5/100 because Overall complexity score: 75\n",
            "\n",
            "Justification:\n",
            "- The code involves loading and preprocessing image data using NumPy and TensorFlow libraries.\n",
            "- It includes building and training multiple neural network models with varying complexity levels.\n",
            "- The code also uses K-Fold cross-validation for model evaluation.\n",
            "- There are multiple hyperparameters that can be tuned to optimize the model performance.\n",
            "- The code involves plotting and visualizing the training accuracy of the models.\n",
            "- The code is well-structured and organized, with clear comments and variable names.\n",
            "The code seems to be moderately complex as it involves data preprocessing, model building, and evaluation. The code includes data cleaning, feature engineering, scaling, logistic regression, confusion matrix, ROC curve, and cutoff analysis. The code also involves plotting graphs for visualization. Overall, I would rate the code around 70 out of 100 in terms of complexity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJDiVQvBTbH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}